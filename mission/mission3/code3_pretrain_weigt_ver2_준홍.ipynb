{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 데이터 크리에이터 캠프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 인공지능은 사람의 마음을 이해할수 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission3. 패션스타일 선호 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Type\n",
    "from collections import defaultdict\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels*self.expansion,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock],\n",
    "        num_classes: int  = 1000\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers == 18: # ResNet18 만을 본 대회에서 사용함으로 18층만 구현\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        print('Dimensions of the last convolutional feature map: ', x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 ResNet-18 모델을 사용하여 각 이미지의 feature vector를 추출  \n",
    "-> 프리트레인 가중치 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 모델 정의\n",
    "class ResNet18FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18FeatureExtractor, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True) # 사전 학습된 가중치\n",
    "        self.features = nn.Sequential(*list(self.resnet18.children())[:-1])  # 마지막 FC 레이어 제외\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3480 entries, 0 to 3479\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   응답자 ID     3480 non-null   int64 \n",
      " 1   train 선호   2215 non-null   object\n",
      " 2   train 비선호  2830 non-null   object\n",
      " 3   valid 선호   1048 non-null   object\n",
      " 4   valid 비선호  1354 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 136.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 불러오기\n",
    "mission2_result = pd.read_csv('../dataset/mission2-2_result_all.csv')\n",
    "\n",
    "# 데이터프레임의 일부 출력\n",
    "mission2_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>train 선호</th>\n",
       "      <th>train 비선호</th>\n",
       "      <th>valid 선호</th>\n",
       "      <th>valid 비선호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66592</td>\n",
       "      <td>T_00253_60_popart_W.jpg, T_00893_90_hiphop_W.j...</td>\n",
       "      <td>T_07452_50_classic_W.jpg, W_02170_50_feminine_...</td>\n",
       "      <td>T_00253_60_popart_W.jpg, W_10028_50_classic_W....</td>\n",
       "      <td>W_02170_50_feminine_W.jpg, W_19352_50_feminine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66721</td>\n",
       "      <td>W_05960_70_hippie_W.jpg</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T_00253_60_popart_W.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   응답자 ID                                           train 선호  \\\n",
       "0   58049                                                NaN   \n",
       "1   62192                                                NaN   \n",
       "2   64213                                                NaN   \n",
       "3   66592  T_00253_60_popart_W.jpg, T_00893_90_hiphop_W.j...   \n",
       "4   66721                            W_05960_70_hippie_W.jpg   \n",
       "\n",
       "                                           train 비선호  \\\n",
       "0                            T_00253_60_popart_W.jpg   \n",
       "1                            T_00253_60_popart_W.jpg   \n",
       "2                            T_00253_60_popart_W.jpg   \n",
       "3  T_07452_50_classic_W.jpg, W_02170_50_feminine_...   \n",
       "4                            T_00253_60_popart_W.jpg   \n",
       "\n",
       "                                            valid 선호  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  T_00253_60_popart_W.jpg, W_10028_50_classic_W....   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           valid 비선호  \n",
       "0                            T_00253_60_popart_W.jpg  \n",
       "1                            T_00253_60_popart_W.jpg  \n",
       "2                            T_00253_60_popart_W.jpg  \n",
       "3  W_02170_50_feminine_W.jpg, W_19352_50_feminine...  \n",
       "4                            T_00253_60_popart_W.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission2_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 데이터에서 선호/비선호 여부에 따라 데이터 있는경우에 추천이 가능하다고 판단하였고  \n",
    "- valid 데이터의 또한 선호/비선호 데이터가 모두 있는 경우를 사용  \n",
    "-> valid 데이터의 경우 선호/비선호 값에 속하는 이미지가 모두 존재해야되지는 않지만 통일성을 위해  \n",
    "데이터가 모두 존재하는 상황에서 아이템 기반 필터링(Item-Based Filtering) 방식 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>train 선호</th>\n",
       "      <th>train 비선호</th>\n",
       "      <th>valid 선호</th>\n",
       "      <th>valid 비선호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66592</td>\n",
       "      <td>T_00253_60_popart_W.jpg, T_00893_90_hiphop_W.j...</td>\n",
       "      <td>T_07452_50_classic_W.jpg, W_02170_50_feminine_...</td>\n",
       "      <td>T_00253_60_popart_W.jpg, W_10028_50_classic_W....</td>\n",
       "      <td>W_02170_50_feminine_W.jpg, W_19352_50_feminine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66469</td>\n",
       "      <td>T_00456_10_sportivecasual_M.jpg, T_00588_10_sp...</td>\n",
       "      <td>T_02958_19_normcore_M.jpg, T_06076_60_mods_M.j...</td>\n",
       "      <td>T_00456_10_sportivecasual_M.jpg, T_01123_90_hi...</td>\n",
       "      <td>W_24553_70_hippie_M.jpg, W_24647_70_hippie_M.j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66513</td>\n",
       "      <td>T_05088_19_normcore_W.jpg, T_07416_19_lounge_W...</td>\n",
       "      <td>T_08306_10_sportivecasual_W.jpg, T_08918_19_no...</td>\n",
       "      <td>W_14828_50_classic_W.jpg</td>\n",
       "      <td>T_06910_50_classic_W.jpg, W_10984_50_feminine_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58251</td>\n",
       "      <td>T_08242_10_sportivecasual_W.jpg, T_08663_19_no...</td>\n",
       "      <td>T_11058_90_lingerie_W.jpg, T_12089_80_powersui...</td>\n",
       "      <td>T_14538_00_cityglam_W.jpg, W_00716_60_minimal_...</td>\n",
       "      <td>W_04101_19_lounge_W.jpg, W_08886_10_athleisure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48094</td>\n",
       "      <td>T_14538_00_cityglam_W.jpg</td>\n",
       "      <td>W_09479_70_hippie_W.jpg</td>\n",
       "      <td>T_14538_00_cityglam_W.jpg</td>\n",
       "      <td>W_09479_70_hippie_W.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>64621</td>\n",
       "      <td>W_29596_10_sportivecasual_M.jpg</td>\n",
       "      <td>W_24250_90_hiphop_M.jpg</td>\n",
       "      <td>W_28925_90_hiphop_M.jpg</td>\n",
       "      <td>W_24250_90_hiphop_M.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>66842</td>\n",
       "      <td>W_27765_60_mods_M.jpg</td>\n",
       "      <td>W_24352_70_hippie_M.jpg</td>\n",
       "      <td>W_27765_60_mods_M.jpg</td>\n",
       "      <td>W_16485_00_metrosexual_M.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>64772</td>\n",
       "      <td>W_32595_60_mods_M.jpg, W_48687_60_mods_M.jpg</td>\n",
       "      <td>W_24470_70_hippie_M.jpg, W_24590_60_mods_M.jpg...</td>\n",
       "      <td>W_33329_50_ivy_M.jpg, W_48687_60_mods_M.jpg</td>\n",
       "      <td>W_24590_60_mods_M.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>64828</td>\n",
       "      <td>W_35091_80_powersuit_W.jpg</td>\n",
       "      <td>W_34027_10_sportivecasual_W.jpg</td>\n",
       "      <td>W_22783_70_hippie_W.jpg, W_35091_80_powersuit_...</td>\n",
       "      <td>W_34027_10_sportivecasual_W.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>67669</td>\n",
       "      <td>W_71920_60_mods_M.jpg</td>\n",
       "      <td>W_52548_50_ivy_M.jpg, W_52586_50_ivy_M.jpg</td>\n",
       "      <td>W_52578_50_ivy_M.jpg</td>\n",
       "      <td>W_52521_50_ivy_M.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     응답자 ID                                           train 선호  \\\n",
       "0     66592  T_00253_60_popart_W.jpg, T_00893_90_hiphop_W.j...   \n",
       "1     66469  T_00456_10_sportivecasual_M.jpg, T_00588_10_sp...   \n",
       "2     66513  T_05088_19_normcore_W.jpg, T_07416_19_lounge_W...   \n",
       "3     58251  T_08242_10_sportivecasual_W.jpg, T_08663_19_no...   \n",
       "4     48094                          T_14538_00_cityglam_W.jpg   \n",
       "..      ...                                                ...   \n",
       "463   64621                    W_29596_10_sportivecasual_M.jpg   \n",
       "464   66842                              W_27765_60_mods_M.jpg   \n",
       "465   64772       W_32595_60_mods_M.jpg, W_48687_60_mods_M.jpg   \n",
       "466   64828                         W_35091_80_powersuit_W.jpg   \n",
       "467   67669                              W_71920_60_mods_M.jpg   \n",
       "\n",
       "                                             train 비선호  \\\n",
       "0    T_07452_50_classic_W.jpg, W_02170_50_feminine_...   \n",
       "1    T_02958_19_normcore_M.jpg, T_06076_60_mods_M.j...   \n",
       "2    T_08306_10_sportivecasual_W.jpg, T_08918_19_no...   \n",
       "3    T_11058_90_lingerie_W.jpg, T_12089_80_powersui...   \n",
       "4                              W_09479_70_hippie_W.jpg   \n",
       "..                                                 ...   \n",
       "463                            W_24250_90_hiphop_M.jpg   \n",
       "464                            W_24352_70_hippie_M.jpg   \n",
       "465  W_24470_70_hippie_M.jpg, W_24590_60_mods_M.jpg...   \n",
       "466                    W_34027_10_sportivecasual_W.jpg   \n",
       "467         W_52548_50_ivy_M.jpg, W_52586_50_ivy_M.jpg   \n",
       "\n",
       "                                              valid 선호  \\\n",
       "0    T_00253_60_popart_W.jpg, W_10028_50_classic_W....   \n",
       "1    T_00456_10_sportivecasual_M.jpg, T_01123_90_hi...   \n",
       "2                             W_14828_50_classic_W.jpg   \n",
       "3    T_14538_00_cityglam_W.jpg, W_00716_60_minimal_...   \n",
       "4                            T_14538_00_cityglam_W.jpg   \n",
       "..                                                 ...   \n",
       "463                            W_28925_90_hiphop_M.jpg   \n",
       "464                              W_27765_60_mods_M.jpg   \n",
       "465        W_33329_50_ivy_M.jpg, W_48687_60_mods_M.jpg   \n",
       "466  W_22783_70_hippie_W.jpg, W_35091_80_powersuit_...   \n",
       "467                               W_52578_50_ivy_M.jpg   \n",
       "\n",
       "                                             valid 비선호  \n",
       "0    W_02170_50_feminine_W.jpg, W_19352_50_feminine...  \n",
       "1    W_24553_70_hippie_M.jpg, W_24647_70_hippie_M.j...  \n",
       "2    T_06910_50_classic_W.jpg, W_10984_50_feminine_...  \n",
       "3    W_04101_19_lounge_W.jpg, W_08886_10_athleisure...  \n",
       "4                              W_09479_70_hippie_W.jpg  \n",
       "..                                                 ...  \n",
       "463                            W_24250_90_hiphop_M.jpg  \n",
       "464                       W_16485_00_metrosexual_M.jpg  \n",
       "465                              W_24590_60_mods_M.jpg  \n",
       "466                    W_34027_10_sportivecasual_W.jpg  \n",
       "467                               W_52521_50_ivy_M.jpg  \n",
       "\n",
       "[468 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 열의 값이 채워져 있는 행만 선택\n",
    "filtered_mission2_result = mission2_result.dropna()\n",
    "\n",
    "# 인덱스 재설정\n",
    "filtered_mission2_result = filtered_mission2_result.reset_index(drop=True)\n",
    "\n",
    "# 결과 출력\n",
    "filtered_mission2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-18 모델을 사용하여 이미지의 feature vector를 추출 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet18FeatureExtractor(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 이미지 feature vector 추출 함수\n",
    "def extract_features(image_path, model, transform):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"File not found: {image_path}\")\n",
    "        return None\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# 이미지 디렉토리 경로\n",
    "train_image_directory = '../dataset/training_image'\n",
    "valid_image_directory = '../dataset/validation_image'\n",
    "\n",
    "# ResNet-18 모델 초기화\n",
    "model = ResNet18FeatureExtractor()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 간 유사도를 계산 및 Validation 데이터 내 응답자의 스타일 선호 여부를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 학습 이미지와 검증 이미지의 디렉토리 경로 설정\n",
    "train_image_directory = '../dataset/training_image'\n",
    "valid_image_directory = '../dataset/validation_image'\n",
    "\n",
    "# 유사도 계산 함수\n",
    "def calculate_similarity(feature1, feature2):\n",
    "    return cosine_similarity([feature1], [feature2])[0][0]\n",
    "\n",
    "# 응답자별 학습 이미지와 검증 이미지의 feature vector 추출 및 저장\n",
    "def extract_respondent_features(mission2_result, model, transform):\n",
    "    respondent_train_features = {}\n",
    "    respondent_valid_features = {}\n",
    "\n",
    "    for index, row in mission2_result.iterrows():\n",
    "        respondent_id = row['응답자 ID']\n",
    "        train_images = []\n",
    "        valid_images = []\n",
    "\n",
    "        if not pd.isna(row['train 선호']):\n",
    "            train_images.extend([(img, '선호') for img in row['train 선호'].split(', ')])\n",
    "        if not pd.isna(row['train 비선호']):\n",
    "            train_images.extend([(img, '비선호') for img in row['train 비선호'].split(', ')])\n",
    "        if not pd.isna(row['valid 선호']):\n",
    "            valid_images.extend(row['valid 선호'].split(', '))\n",
    "        if not pd.isna(row['valid 비선호']):\n",
    "            valid_images.extend(row['valid 비선호'].split(', '))\n",
    "\n",
    "        respondent_train_features[respondent_id] = {}\n",
    "        respondent_valid_features[respondent_id] = {}\n",
    "\n",
    "        for train_image, preference in train_images:\n",
    "            image_path = os.path.join(train_image_directory, train_image).replace('\\\\', '/')\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"File not found: {image_path}\")\n",
    "                continue\n",
    "            image_id = train_image.split('_')[1]\n",
    "            feature = extract_features(image_path, model, transform)\n",
    "            if feature is not None:\n",
    "                respondent_train_features[respondent_id][image_id] = (feature, preference)\n",
    "\n",
    "        for valid_image in valid_images:\n",
    "            image_path = os.path.join(valid_image_directory, valid_image).replace('\\\\', '/')\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"File not found: {image_path}\")\n",
    "                continue\n",
    "            image_id = valid_image.split('_')[1]\n",
    "            feature = extract_features(image_path, model, transform)\n",
    "            if feature is not None:\n",
    "                respondent_valid_features[respondent_id][image_id] = feature\n",
    "\n",
    "    return respondent_train_features, respondent_valid_features\n",
    "\n",
    "# 응답자별 학습 이미지와 검증 이미지의 feature vector 추출\n",
    "respondent_train_features, respondent_valid_features = extract_respondent_features(filtered_mission2_result, model, transform)\n",
    "\n",
    "# Validation 데이터 내 응답자의 스타일 선호 여부 예측\n",
    "def predict_preference(respondent_train_features, respondent_valid_features, threshold=0.5):\n",
    "    predictions = {}\n",
    "    for respondent_id, valid_features in respondent_valid_features.items():\n",
    "        respondent_predictions = {}\n",
    "        for valid_image_id, valid_feature in valid_features.items():\n",
    "            similarities = {'선호': [], '비선호': []}\n",
    "            for train_image_id, (train_feature, preference) in respondent_train_features[respondent_id].items():\n",
    "                similarity = calculate_similarity(valid_feature, train_feature)\n",
    "                similarities[preference].append(similarity)\n",
    "            # 모든 유사도를 사용하여 평균 계산\n",
    "            if len(similarities['선호']) == 0 and len(similarities['비선호']) == 0:\n",
    "                preference_score = 0  # 기본값 설정\n",
    "            else:\n",
    "                preference_score = (sum(similarities['선호']) - sum(similarities['비선호'])) / (len(similarities['선호']) + len(similarities['비선호']))\n",
    "            respondent_predictions[valid_image_id] = '선호' if preference_score > threshold else '비선호'\n",
    "        predictions[respondent_id] = respondent_predictions\n",
    "    return predictions\n",
    "\n",
    "# 예측 수행\n",
    "predictions = predict_preference(respondent_train_features, respondent_valid_features, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_preference(respondent_train_features, respondent_valid_features, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# 성능 측정 (예시로 정확도 계산)\n",
    "def calculate_accuracy(predictions, mission2_result):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for index, row in mission2_result.iterrows():\n",
    "        respondent_id = row['응답자 ID']\n",
    "        if respondent_id not in predictions:\n",
    "            continue\n",
    "        for valid_image in row['valid 선호'].split(', ') if not pd.isna(row['valid 선호']) else []:\n",
    "            valid_image_id = valid_image.split('_')[1]\n",
    "            if valid_image_id in predictions[respondent_id]:\n",
    "                total += 1\n",
    "                if predictions[respondent_id][valid_image_id] == '선호':\n",
    "                    correct += 1\n",
    "        for valid_image in row['valid 비선호'].split(', ') if not pd.isna(row['valid 비선호']) else []:\n",
    "            valid_image_id = valid_image.split('_')[1]\n",
    "            if valid_image_id in predictions[respondent_id]:\n",
    "                total += 1\n",
    "                if predictions[respondent_id][valid_image_id] == '비선호':\n",
    "                    correct += 1\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = calculate_accuracy(predictions, mission2_result)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
