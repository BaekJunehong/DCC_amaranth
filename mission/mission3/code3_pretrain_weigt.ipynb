{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 데이터 크리에이터 캠프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 인공지능은 사람의 마음을 이해할수 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission3. 패션스타일 선호 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Type\n",
    "from collections import defaultdict\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels*self.expansion,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock],\n",
    "        num_classes: int  = 1000\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers == 18: # ResNet18 만을 본 대회에서 사용함으로 18층만 구현\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        print('Dimensions of the last convolutional feature map: ', x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 ResNet-18 모델을 사용하여 각 이미지의 feature vector를 추출  \n",
    "-> 프리트레인 가중치 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 모델 정의\n",
    "class ResNet18FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18FeatureExtractor, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True) # 사전 학습된 가중치\n",
    "        self.features = nn.Sequential(*list(self.resnet18.children())[:-1])  # 마지막 FC 레이어 제외\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4116 entries, 0 to 4115\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   응답자 ID     4116 non-null   int64 \n",
      " 1   train 선호   3081 non-null   object\n",
      " 2   train 비선호  3416 non-null   object\n",
      " 3   valid 선호   1396 non-null   object\n",
      " 4   valid 비선호  1595 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 160.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 불러오기\n",
    "mission2_result = pd.read_csv('../dataset/mission2-2_result_all.csv')\n",
    "\n",
    "# 데이터프레임의 일부 출력\n",
    "mission2_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>응답자 ID</th>\n",
       "      <th>train 선호</th>\n",
       "      <th>train 비선호</th>\n",
       "      <th>valid 선호</th>\n",
       "      <th>valid 비선호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52002</td>\n",
       "      <td>W_24111_70_hippie_M.jpg</td>\n",
       "      <td>T_00004_90_hiphop_M.jpg, T_03007_10_sportiveca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66699</td>\n",
       "      <td>T_00004_90_hiphop_M.jpg, T_01568_50_ivy_M.jpg,...</td>\n",
       "      <td>T_03643_00_metrosexual_M.jpg, T_06009_10_sport...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66797</td>\n",
       "      <td>T_01259_10_sportivecasual_M.jpg, T_16092_10_sp...</td>\n",
       "      <td>T_00004_90_hiphop_M.jpg, W_15467_70_hippie_M.j...</td>\n",
       "      <td>T_08486_10_sportivecasual_M.jpg, W_23958_60_mo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66684</td>\n",
       "      <td>T_00047_19_normcore_M.jpg, T_03699_90_hiphop_M...</td>\n",
       "      <td>T_00007_19_normcore_M.jpg, W_51917_00_metrosex...</td>\n",
       "      <td>W_15341_60_mods_M.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66817</td>\n",
       "      <td>T_00012_19_normcore_M.jpg, T_04506_90_hiphop_M...</td>\n",
       "      <td>T_03624_90_hiphop_M.jpg, T_04522_90_hiphop_M.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W_17135_00_metrosexual_M.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   응답자 ID                                           train 선호  \\\n",
       "0   52002                            W_24111_70_hippie_M.jpg   \n",
       "1   66699  T_00004_90_hiphop_M.jpg, T_01568_50_ivy_M.jpg,...   \n",
       "2   66797  T_01259_10_sportivecasual_M.jpg, T_16092_10_sp...   \n",
       "3   66684  T_00047_19_normcore_M.jpg, T_03699_90_hiphop_M...   \n",
       "4   66817  T_00012_19_normcore_M.jpg, T_04506_90_hiphop_M...   \n",
       "\n",
       "                                           train 비선호  \\\n",
       "0  T_00004_90_hiphop_M.jpg, T_03007_10_sportiveca...   \n",
       "1  T_03643_00_metrosexual_M.jpg, T_06009_10_sport...   \n",
       "2  T_00004_90_hiphop_M.jpg, W_15467_70_hippie_M.j...   \n",
       "3  T_00007_19_normcore_M.jpg, W_51917_00_metrosex...   \n",
       "4  T_03624_90_hiphop_M.jpg, T_04522_90_hiphop_M.j...   \n",
       "\n",
       "                                            valid 선호  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  T_08486_10_sportivecasual_M.jpg, W_23958_60_mo...   \n",
       "3                              W_15341_60_mods_M.jpg   \n",
       "4                                                NaN   \n",
       "\n",
       "                      valid 비선호  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4  W_17135_00_metrosexual_M.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission2_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-18 모델을 사용하여 이미지의 feature vector를 추출 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 이미지 feature vector 추출 함수\n",
    "def extract_features(image_path, model, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# 이미지 디렉토리 경로\n",
    "train_image_directory = '../dataset/training_image'\n",
    "valid_image_directory = '../dataset/validation_image'\n",
    "\n",
    "# ResNet-18 모델 초기화\n",
    "model = ResNet18FeatureExtractor()\n",
    "model.eval()\n",
    "\n",
    "# 이미지 feature vector 추출 및 저장\n",
    "train_features = {}\n",
    "valid_features = {}\n",
    "\n",
    "for image_name in os.listdir(train_image_directory):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = os.path.join(train_image_directory, image_name)\n",
    "        image_id = image_name.split('_')[1]\n",
    "        train_features[image_id] = extract_features(image_path, model, transform)\n",
    "\n",
    "for image_name in os.listdir(valid_image_directory):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = os.path.join(valid_image_directory, image_name)\n",
    "        image_id = image_name.split('_')[1]\n",
    "        valid_features[image_id] = extract_features(image_path, model, transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 간 유사도를 계산 및 Validation 데이터 내 응답자의 스타일 선호 여부를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 유사도 계산 함수\n",
    "def calculate_similarity(feature1, feature2):\n",
    "    return cosine_similarity([feature1], [feature2])[0][0]\n",
    "\n",
    "# Validation 데이터 내 응답자의 스타일 선호 여부 예측\n",
    "def predict_preference(mission2_result, valid_features, train_features, threshold=0.5):\n",
    "    predictions = {}\n",
    "    for index, row in mission2_result.iterrows():\n",
    "        respondent_id = row['응답자 ID']\n",
    "        if pd.isna(row['valid 선호']) and pd.isna(row['valid 비선호']):\n",
    "            continue\n",
    "        valid_images = []\n",
    "        if not pd.isna(row['valid 선호']):\n",
    "            valid_images.extend(row['valid 선호'].split(', '))\n",
    "        if not pd.isna(row['valid 비선호']):\n",
    "            valid_images.extend(row['valid 비선호'].split(', '))\n",
    "        \n",
    "        respondent_predictions = {}\n",
    "        for valid_image in valid_images:\n",
    "            valid_image_id = valid_image.split('_')[1]\n",
    "            if valid_image_id in valid_features:\n",
    "                valid_feature = valid_features[valid_image_id]\n",
    "                similarities = []\n",
    "                for train_image_id, train_feature in train_features.items():\n",
    "                    similarity = calculate_similarity(valid_feature, train_feature)\n",
    "                    similarities.append((train_image_id, similarity))\n",
    "                similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "                top_similarities = similarities[:5]  # 상위 5개 유사도 사용\n",
    "                preference_score = sum([sim for _, sim in top_similarities]) / len(top_similarities)\n",
    "                respondent_predictions[valid_image] = '선호' if preference_score > threshold else '비선호'\n",
    "        predictions[respondent_id] = respondent_predictions\n",
    "    return predictions\n",
    "\n",
    "# 예측 수행\n",
    "predictions = predict_preference(mission2_result, valid_features, train_features, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "# 성능 측정 (예시로 정확도 계산)\n",
    "def calculate_accuracy(predictions, valid_labels):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for respondent_id, respondent_predictions in predictions.items():\n",
    "        for image_name, predicted_label in respondent_predictions.items():\n",
    "            image_id = image_name.split('_')[1]  # 이미지 ID 추출\n",
    "            if image_id in valid_labels:\n",
    "                total += 1\n",
    "                if predicted_label == valid_labels[image_id]:\n",
    "                    correct += 1\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# Validation 데이터의 실제 라벨 로드\n",
    "valid_labels = {}\n",
    "valid_label_directory = '../dataset/validation_label'\n",
    "for filename in os.listdir(valid_label_directory):\n",
    "    if filename.endswith('.json'):\n",
    "        filepath = os.path.join(valid_label_directory, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            image_id = data['item']['imgName'].split('_')[1]\n",
    "            Q5 = data['item']['survey']['Q5']\n",
    "            valid_labels[image_id] = '선호' if Q5 == 2 else '비선호'\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = calculate_accuracy(predictions, valid_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
